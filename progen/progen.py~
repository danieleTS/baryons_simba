
# Loops over all snapshots (in reverse) from last_snap to first_snap, sets up snapshot pairs [snapfile1,snapfile2] to find progenitors.
# For each galaxy in snapfile1, finds progenitors in snapfile2.  progenitors are defined as having the most star particles in common.
# Writes the progenitor IDs into the "progen_index" field in the galaxies object in the Caesar file associated with snapfile1.
# Writes the second-most common progenitor IDs into the "progen_index2" field in the galaxies object in the Caesar file associated with snapfile1.
# You can either daisychain the snaphots or always use last_snap for snapfile1.
# Works with multi-processor via OpenMP; doesn't help much because most of the time is in the sorting (not yet parallel).  It's fast tho!
# Last modified: Romeel Dave 18 Feb 2019

import caesar
from pygadgetreader import *
import numpy as np
from scipy import stats
import time
import sys
import os

MODEL = sys.argv[1]
WIND = sys.argv[2]
if len(sys.argv)==4: nproc = int(sys.argv[3])
else: nproc = 1

GDIR = 'Groups'
mode = 'daisychain'  # 'daisychain' to link each snapshot to its previous or 'refsnap' to link a single given snapshot to all previous
BASEDIR = '/home/rad/data/%s/%s'%(MODEL,WIND)

first_snap = 10
last_snap = 151  # final snapshot to begin progening from

min_in_common = 0.99  # require at least this fraction of particles in common between galaxy and its progenitor to be called a true progenitor

# Routine to find progenitor for given galaxy ig
def get_galaxy_prog(ig,PID_curr,id_prog,ig_prog,objs1,parttype):
    if parttype == 'gas' : objlist = objs1.glist
    elif parttype == 'dm' : objlist = objs1.dmlist
    elif parttype == 'star' : objlist = objs1.slist
    elif parttype == 'bndry' : objlist = objs1.bhlist
    ids = [PID_curr[i] for i in objlist]
    prog_ind = np.searchsorted(id_prog,ids) # bisection search to find closest ID in prog
    for i in range(len(prog_ind)):  # handle some very occasional weirdness
        if prog_ind[i] >= len(id_prog): prog_ind[i] = len(id_prog)-1
    prog_ind = prog_ind[id_prog[prog_ind]==ids]  # find progenitor IDs that match star IDs in galaxy ig
    ig_matched = ig_prog[prog_ind]  # galaxy numbers of matched progenitor IDs
    if len(ig_matched)>int(min_in_common*len(ids)):
        modestats = stats.mode(ig_matched) # find prog galaxy id with most matches
        prog_index_ig = modestats[0][0]  # prog_index stores prog galaxy numbers
        ig_matched = ig_matched[(ig_matched!=prog_index_ig)]  # remove the first-most common galaxy, recompute mode
    else: prog_index_ig = -1
    if len(ig_matched)>0:
        modestats = stats.mode(ig_matched) # find prog galaxy id with second-most matches
        prog_index_ig2 = modestats[0][0]  # now we have the second progenitor
    else: prog_index_ig2 = -1
    #if ig<10: print ig,prog_index_ig,prog_index_ig2
    return prog_index_ig,prog_index_ig2

# Routine to load in particle IDs from snapshot
def load_IDs(snap1,snap2,t0,parttype='star'):
    PID_curr = np.array(readsnap(snap1,'pid',parttype),dtype=np.uint64) # particle IDs in current snapshot
    PID_prog = np.array(readsnap(snap2,'pid',parttype),dtype=np.uint64) # particle IDs in progenitor snapshot
    try:  # if it's gas/star/BH in newer (Simba) sims, it will contain ID_Generations
        IDgen_curr = np.array(readsnap(snap1,'ID_Generations',parttype)-1,dtype=np.uint64) # ID generation info for duplicate IDs
        IDgen_prog = np.array(readsnap(snap2,'ID_Generations',parttype)-1,dtype=np.uint64)
    except:  # older snapshots (like Mufasa) and DM do not contain ID_Generations
        IDgen_curr = np.zeros(len(PID_curr))
        IDgen_prog = np.zeros(len(PID_prog))
    print('progen : Read ID info for %d current %s parts and %d progenitor %s parts [t=%g s]'%(len(PID_curr),parttype,len(PID_prog),parttype,time.time()-t0))
    maxid = max(max(PID_curr),max(PID_prog))
    #print len(IDgen_curr[IDgen_curr>0])
    PID_curr += maxid*IDgen_curr  # ensure no duplicate IDs by encoding the IDgen info
    PID_prog += maxid*IDgen_prog

    return PID_curr,PID_prog

# Routine to find progenitors for all galaxies in snapshot
def find_progens(snap1,snap2,obj1,obj2,nproc,t0,objtype='galaxies',parttype='star'):
    PID_curr,PID_prog = load_IDs(snap1,snap2,t0,parttype=parttype) # Gather all the IDs and associated galaxy/halo numbers from the progenitor snapshot
    if objtype == 'galaxies':
        objects1=obj1.galaxies
        objects2=obj2.galaxies
    elif objtype == 'halos':
        objects1=obj1.halos
        objects2=obj2.halos
    else: sys.exit('progen : ERROR: objtype %s not valid'%objtype)

    ngal_curr = len(objects1)
    ngal_prog = len(objects2)
    id_prog = np.zeros(len(PID_prog),dtype=np.uint64)  # particle IDs of progenitor particles
    ig_prog = np.zeros(len(PID_prog),dtype=int)        # galaxy IDs of progenitor particles
    count = 0
    for ig in range(ngal_prog):
        # Gather list of progenitor particles and associated galaxy numbers
        if parttype == 'gas' : objlist = objects2[ig].glist
        elif parttype == 'dm' : objlist = objects2[ig].dmlist
        elif parttype == 'star' : objlist = objects2[ig].slist
        elif parttype == 'bndry' : objlist = objects2[ig].bhlist
        else : sys.exit('progen : parttype %s not recognized -- exiting'%parttype)
        for ilist in range(len(objlist)):
            ipart = objlist[ilist]
            id_prog[count] = PID_prog[ipart]
            ig_prog[count] = ig
            count += 1
        # List comprehension version below is significantly slower
        #ids = [PID_prog[i] for i in obj2.galaxies[ig].slist]
        #igs = [ig for i in obj2.galaxies[ig].slist]
        #id_prog = np.concatenate((id_prog,ids))
        #ig_prog = np.concatenate((ig_prog,igs))
    print('progen : Gathered ID info for %d progenitor %s out of %d total %s [t=%g s]'%(count,parttype,len(PID_curr),parttype,time.time()-t0))
    id_prog = id_prog[:count]
    ig_prog = ig_prog[:count]

    # Sort the progenitor IDs and galaxy numbers for faster searching
    isort_prog = np.argsort(id_prog,kind='quicksort')
    id_prog = id_prog[isort_prog]  # this stores the progenitor star IDs
    ig_prog = ig_prog[isort_prog]  # this stores the galaxy IDs for the progenitor particles
    print('progen : Sorted progenitor IDs [t=%g s]'%(time.time()-t0))

    # Loop over galaxies in current snapshot
    if nproc>1: 
        prog_index_tmp = Parallel(n_jobs=nproc)(delayed(get_galaxy_prog)(ig,PID_curr,id_prog,ig_prog,objects1[ig],parttype) for ig in range(ngal_curr))
        prog_index_tmp = np.array(prog_index_tmp,dtype=int)
        prog_index = np.array(prog_index_tmp.T[0],dtype=int)
        prog_index2 = np.array(prog_index_tmp.T[1],dtype=int)
    else:
        prog_index = np.zeros(ngal_curr,dtype=int)
        prog_index2 = np.zeros(ngal_curr,dtype=int)
        for ig in range(ngal_curr):
            prog_index[ig],prog_index2[ig] = get_galaxy_prog(ig,PID_curr,id_prog,ig_prog,objects1[ig],parttype)

    # Print some stats and return the indices
    try:
        print('progen : Out of',ngal_curr,objtype,' most common prog',stats.mode(prog_index[prog_index>=0])[0][0],'appeared',stats.mode(prog_index[prog_index>=0])[1][0],'times.',stats.mode(prog_index[prog_index<0])[1][0],'had no progenitors.')
    except:
        print('0 had no progenitors.')
    return prog_index,prog_index2

#=========================================================
# MAIN DRIVER ROUTINE
#=========================================================

if __name__ == '__main__':

    # Set up pairs;
    if not os.path.isfile('%s/snap_%s_%03d.hdf5' % (BASEDIR,MODEL,last_snap)):
        sys.exit('Reference_snap %d does not exist'%last_snap)
    allsnaps = np.arange(last_snap,first_snap-1,-1)
    # find snapshots with caesar files that exist in the directory, in reverse order
    snapnums = []
    for i in allsnaps:
        if os.path.isfile('%s/snap_%s_%03d.hdf5' % (BASEDIR,MODEL,i)) and os.path.isfile('%s/%s/%s_%03d.hdf5' % (BASEDIR,GDIR,MODEL,i)):
            snapnums.append(i)
    #print('Found these snapshots with caesar files: %s'%snapnums)
    # set up pairs to progen
    pairs = []
    if mode=='refsnap':  prevsnap = snapnums[0]  # find progenitors based on a single reference (final) snapshot
    for i in range(len(snapnums)-1):
        if mode=='daisychain':  prevsnap = snapnums[i] # daisy-chain progenitors in each snapshot to the previous snapshot
        pairs.append([prevsnap,snapnums[i+1]])

    print('progen : Doing snapshot pairs: %s'%pairs)

# Set up multiprocessing; note: this doesn't help much, because this only parallelizes over galaxy ID searches, not the sorting.
    if nproc == 0:   # use all available cores
        num_cores = multiprocessing.cpu_count()
    if nproc != 1:   # if multi-core, set up Parallel processing
        import multiprocessing
        from joblib import Parallel, delayed
        from functools import partial
        num_cores = multiprocessing.cpu_count()
        if nproc < 0: print('progen : Using %d cores (all but %d)'%(num_cores+nproc+1,-nproc-1) )
        if nproc > 1: print('progen : Using %d of %d cores'%(nproc,num_cores))
        else: print('progen : Using single core')

# loop over pairs to find progenitors
    t0 = time.time()
    prev_pair = [-1,-1]
    for pair in pairs:
    
        print('progen : Doing pair %s [t=%g s]'%(pair,np.round(time.time()-t0,3)))
        if pair[0] == prev_pair[1]:  # don't have to reload if we already have this object from the previous iteration
            snapfile1 = snapfile2
            caesarfile1 = caesarfile2
            obj1 = obj2
        else:
            snapfile1 = '%s/snap_%s_%03d.hdf5' % (BASEDIR,MODEL,pair[0])   # current snapshot
            caesarfile1 = '%s/%s/%s_%03d.hdf5' % (BASEDIR,GDIR,MODEL,pair[0])
            obj1 = caesar.load(caesarfile1,LoadHalo=False)
        snapfile2 = '%s/snap_%s_%03d.hdf5' % (BASEDIR,MODEL,pair[1])   # progenitor snapshot
        caesarfile2 = '%s/%s/%s_%03d.hdf5' % (BASEDIR,GDIR,MODEL,pair[1])
        obj2 = caesar.load(caesarfile2,LoadHalo=False)
        prog_index,prog_index2 = find_progens(snapfile1,snapfile2,obj1,obj2,nproc,t0)  # find galaxies with most particles in common in progenitor snapshot
    
        # append progenitor info to caesar file
        caesar_file = obj1.data_file  # file to write progen info to
        data_type = 'galaxy'
        try:
            caesar.progen.write_progen_data(obj1, prog_index, data_type, caesar_file, 'progen_index')
        except:
            caesar.progen.rewrite_progen_data(obj1, prog_index, data_type, caesar_file, 'progen_index')
        try:
            caesar.progen.write_progen_data(obj1, prog_index2, data_type, caesar_file, 'progen_index2')
        except:
            caesar.progen.rewrite_progen_data(obj1, prog_index2, data_type, caesar_file, 'progen_index2')
    
        print('progen : Wrote info to caesar file %s [t=%g s]'%(caesar_file,time.time()-t0))

        prev_pair = pair


